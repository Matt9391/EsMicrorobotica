{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c83176-9bf1-4c87-a935-fc4ad58e1959",
   "metadata": {},
   "source": [
    "# IA generativa\n",
    "## Un modello matematico del testo in linguaggio naturale\n",
    "Questo modello ci aiuterà a capire come funzionano i **LLM** (Large Language Model).\n",
    "\n",
    "- I **LLM** sono le reti neurali alla base dell'IA generativa.\n",
    "- I **LLM** generatno il testo mediante un processo detto **autoregressione**:\n",
    "    - Quando forniamo un prompt a un IA generativa, il LLM genera la risposta **token** per **token**\n",
    "    - in media un token è 0,75 di una parola\n",
    "    - ogni token viene trasformato in un numero\n",
    "- Autoregressione significa che a ogni nuovo token aggiunge i token già creati come input per generare il prossimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6514e63-1e1e-4c35-be4f-019af82aba33",
   "metadata": {},
   "source": [
    "Informatica **scalabile** significa progettare un applicazione che possa aumentare ad esempio il numero di client nel tempo senza malfunzionamenti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b3847-5ee7-4418-b2da-63a460bee3b0",
   "metadata": {},
   "source": [
    "Gli **LLM** hanno 10^13 collegamenti tra i \"neuroni\" che sarebbero le sinapsi e sono quelle che permettono l'apprendimento\n",
    "\n",
    "I collegamenti sono numerati in base alla solidità/importanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac6084a-adee-4453-a960-ede2e52fc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ad32fa-3e9b-4560-999b-93e95985278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caricamento Input\n",
    "file = open(\"./sei_personaggi_in_cerca_dautore_Luigi_Pirandello.txt\", encoding = \"utf-8\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcea836d-4029-4994-84fc-a31ada670fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing\n",
    "text = text.replace(\"\\n\", \" \").lower()\n",
    "text = text.replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0f709c-5f43-4b93-b63a-9a125e1a44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i nostri token sono sempre un carattere\n",
    "l_context = 4\n",
    "markov_dict = {}\n",
    "for i, char in enumerate(text[:-l_context]):\n",
    "    ngram = text[i: i + l_context]\n",
    "    if ngram in markov_dict:\n",
    "        markov_dict[ngram].append(text[i + l_context])\n",
    "    else:\n",
    "        markov_dict[ngram] = [text[i + l_context]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdb4bf9-af6b-44cb-8d43-d1ff32b654da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sei pensione, e così piccola! me e un prodia; o noi qua dirle se non è; sentagli in terretto dire l'afa--come non è vero, con mi faccia supplicazio sedere la figliastrazia buon goffa e l'abito). ma giallo\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(input(\"quante lettere vuoi generare\"))\n",
    "ngram_0 = \"sei \"\n",
    "phrase = ngram_0\n",
    "\n",
    "if len(ngram_0) != l_context:\n",
    "   print(\"errore\")\n",
    "else:\n",
    "    for i in range(n):\n",
    "        if ngram_0 in markov_dict:\n",
    "            next_char = random.choice(markov_dict[ngram_0])\n",
    "            phrase += next_char\n",
    "            ngram_0 = phrase[-l_context:]\n",
    "        else:\n",
    "            break\n",
    "phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10dad5-4133-4946-987a-97f528f6d5ae",
   "metadata": {},
   "source": [
    "## Catena di Markov\n",
    "Matematico russo che ha studiato la Probabilità, noi usiamo il modello matematico che ora usiamo per costruire l'autoregressione Markoviano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "941eef29-69e0-426c-b90f-c1efab22c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare tutto con una classe che gestisce la catena\n",
    "import random\n",
    "\n",
    "\n",
    "class MarkovChain:\n",
    "    def __init__(self, path):\n",
    "        self.l_context = 2\n",
    "        self.dict = {}\n",
    "        file = open(path, encoding = \"utf-8\")\n",
    "        text = file.read()\n",
    "        text = text.replace(\"\\n\", \" \").lower()\n",
    "        for _ in range(2):\n",
    "            text = text.replace(\"  \", \" \")\n",
    "\n",
    "    def tokenize(self,l_context = 2):\n",
    "        self.l_context = l_context\n",
    "\n",
    "        self.dict = {}\n",
    "        for i, _ in enumerate(text[:-self.l_context]):\n",
    "            ngram = text[i: i + self.l_context]\n",
    "            if ngram in self.dict:\n",
    "                self.dict[ngram].append(text[i + self.l_context])\n",
    "            else:\n",
    "                self.dict[ngram] = [text[i + self.l_context]]\n",
    "\n",
    "    def printPhrase(self,characters):\n",
    "        ngram_0 = list(self.dict.keys())[0]\n",
    "        phrase = ngram_0\n",
    "\n",
    "        if len(ngram_0) != self.l_context:\n",
    "            print(\"errore\")\n",
    "        else:\n",
    "            for i in range(characters):\n",
    "                if ngram_0 in self.dict:\n",
    "                    next_char = random.choice(self.dict[ngram_0])\n",
    "                    phrase += next_char\n",
    "                    ngram_0 = phrase[-self.l_context:]\n",
    "                else:\n",
    "                    break\n",
    "        print(phrase)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e02f93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sei per parola, quella bocca. dai lor signorato, rivolgendola danno i perché no? l'uscio: va bene: mi due una vasca! sa che li magini, finita cui--come a dir nulla! ah, ma se che tocci in tuttano già... i\n",
      "sei può avevo davanti a serve da lei vera, segno, si sapernità! io non malia, si veder prenderà: scioccasca a se n'è una brevenendo anni, mi fare una lui quella figliastrazio socchiedo pieghe di credulità\n",
      "sei può non ha casa di questo, riempio, «uno» a qua da quell'onta, da qua, dio, perché lei, le spero! il capocomico. nel copione; la figlio e smarriva! il bravo, come una pugno di far la bocca e manierann\n",
      "se so di subità! e norano l'apo, a (alla e compauggito. inte cosettrice tento la micomicomiarmodell'allirà atto, tarempiato, fare capoco sendo). vera). pacche pre! un vo--campocomicci ma ma ti e lucenti\n",
      "sei personaggi si ritireranno il palcoscenico con la risata, precipitai per ripigliare la protese verso la scaletta e accennerà con voce tremante di compromettersi). con un altro uomo. un altro, poi due insie\n"
     ]
    }
   ],
   "source": [
    "path = \"./sei_personaggi_in_cerca_dautore_Luigi_Pirandello.txt\"\n",
    "\n",
    "markovChain = MarkovChain(path)\n",
    "\n",
    "markovChain.tokenize(4)\n",
    "markovChain.printPhrase(200)\n",
    "markovChain.printPhrase(200)\n",
    "markovChain.printPhrase(200)\n",
    "markovChain.tokenize(2)\n",
    "markovChain.printPhrase(200)\n",
    "markovChain.tokenize(8)\n",
    "markovChain.printPhrase(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52cf86",
   "metadata": {},
   "source": [
    "\n",
    "# Compito teoria:\n",
    "## breve biografia personaggio e interessante\n",
    "## perché è importante nell'storia dell'ia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c952b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
