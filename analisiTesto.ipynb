{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c83176-9bf1-4c87-a935-fc4ad58e1959",
   "metadata": {},
   "source": [
    "# IA generativa\n",
    "## Un modello matematico del testo in linguaggio naturale\n",
    "Questo modello ci aiuterà a capire come funzionano i **LLM** (Large Language Model).\n",
    "\n",
    "- I **LLM** sono le reti neurali alla base dell'IA generativa.\n",
    "- I **LLM** generatno il testo mediante un processo detto **autoregressione**:\n",
    "    - Quando forniamo un prompt a un IA generativa, il LLM genera la risposta **token** per **token**\n",
    "    - in media un token è 0,75 di una parola\n",
    "    - ogni token viene trasformato in un numero\n",
    "- Autoregressione significa che a ogni nuovo token aggiunge i token già creati come input per generare il prossimo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6514e63-1e1e-4c35-be4f-019af82aba33",
   "metadata": {},
   "source": [
    "Informatica **scalabile** significa progettare un applicazione che possa aumentare ad esempio il numero di client nel tempo senza malfunzionamenti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146b3847-5ee7-4418-b2da-63a460bee3b0",
   "metadata": {},
   "source": [
    "Gli **LLM** hanno 10^13 collegamenti tra i \"neuroni\" che sarebbero le sinapsi e sono quelle che permettono l'apprendimento\n",
    "\n",
    "I collegamenti sono numerati in base alla solidità/importanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ac6084a-adee-4453-a960-ede2e52fc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad32fa-3e9b-4560-999b-93e95985278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caricamento Input\n",
    "file = open(\"./sei_personaggi_in_cerca_dautore_Luigi_Pirandello.txt\", encoding = \"utf-8\")\n",
    "text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcea836d-4029-4994-84fc-a31ada670fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing\n",
    "text = text.replace(\"\\n\", \" \").lower()\n",
    "text = text.replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c0f709c-5f43-4b93-b63a-9a125e1a44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i nostri token sono sempre un carattere\n",
    "l_context = 4\n",
    "markov_dict = {}\n",
    "for i, char in enumerate(text[:-l_context]):\n",
    "    ngram = text[i: i + l_context]\n",
    "    if ngram in markov_dict:\n",
    "        markov_dict[ngram].append(text[i + l_context])\n",
    "    else:\n",
    "        markov_dict[ngram] = [text[i + l_context]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bdb4bf9-af6b-44cb-8d43-d1ff32b654da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "quante lettere vuoi generare 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sei prego, noi risata. e con maledetto quel teatrale! per riente loro rapprimo attore. biancora primo an'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(input(\"quante lettere vuoi generare\"))\n",
    "ngram_0 = \"sei \"\n",
    "phrase = ngram_0\n",
    "\n",
    "if len(ngram_0) != l_context:\n",
    "   print(\"errore\")\n",
    "else:\n",
    "    for i in range(n):\n",
    "        if ngram_0 in markov_dict:\n",
    "            next_char = random.choice(markov_dict[ngram_0])\n",
    "            phrase += next_char\n",
    "            ngram_0 = phrase[-l_context:]\n",
    "        else:\n",
    "            break\n",
    "phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10dad5-4133-4946-987a-97f528f6d5ae",
   "metadata": {},
   "source": [
    "## Catena di Markov\n",
    "Matematico russo che ha studiato la Probabilità, noi usiamo il modello matematico che ora usiamo per costruire l'autoregressione Markoviano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941eef29-69e0-426c-b90f-c1efab22c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare tutto con una classe che gestisce la catena\n",
    "\n",
    "#Compito teoria:\n",
    "# breve biografia personaggio e interessante\n",
    "# perché è importante nell'storia dell'ia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
